milestones=[40,80]	
lr = 5e-5
AdamW
MultiStepLR
Cross_Entropy
解冻最后一层layer2和layer3和layer4和fc进行训练
batch_size = 16
改回图片大小为224
gamma 改为 0.1
weight_decay 改为 1e-3

改用了更大的模型resnext101_64x4d，acc没有什么变化，loss出现后期大幅波动的情况

检查代码区别，下面将模型改为resnext101_32x8d，然后将随机种子改为1试一下

依旧没有什么变化

试一下别人的数据预处理

还真行，有79%了，但是早停了，下一步将图片再次改为256做比较

改完图片大小有80%了，但是epoch=30前就停下来了
可以将milestones改小，改回[20,40,60]试试


	
	

