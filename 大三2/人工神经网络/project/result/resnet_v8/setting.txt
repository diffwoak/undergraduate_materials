milestones=[40,80]	
lr = 5e-5
AdamW
MultiStepLR
Cross_Entropy
解冻最后一层layer2和layer3和layer4和fc进行训练
batch_size = 16
改回图片大小为224
gamma 改为 0.1


下一步：改正则化相关系数，现在观察loss图有过拟合的感觉

	weight_decay 改为 1e-3
	

