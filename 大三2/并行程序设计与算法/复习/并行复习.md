## 并行复习

#### 复习内容

- 课本上例子
- ppt概念、习题
- 编程题（平时理论作业、实验作业）
- 接口（有说明）
- 概念（cuda、openMP解释名词含有）

各个班级交集 ➡ 不会考太偏的

先处理干净cuda部分课件

#### 课程总结

- 为什么需要并行？
  - 计算机已经很难变得“更快”：频率提升已经（几乎）停止
  - 计算机正变得“更宽”：并发、并行、分布式
- 串行软硬件
  - 多级存储架构（为什么需要？）
  - 进程与线程
- 并行软硬件
  - 弗林分类法（Flynn’s Taxonomy）
  - 共享内存系统 vs 分布式内存系统
    - 各自的硬件架构和编程特性是什么？
  - 如何分析、评估并行程序的性能？

- 具体编程框架
  - 如何**同步**，如何**通信**（交换数据），如何**保证结果正确**？
  - 基本概念：同步与阻塞、通信、竞争条件、进程/线程安全
    - 在不同框架下分别理解这几个概念及其联系
    - 对比不同框架的语境下，这几个概念如何实现，及其重要性
  - MPI（分布式内存）：通信（点对点 vs 集合）
  - Pthreads & OpenMP（共享内存）：同步机制；变量作用域
  - CUDA：线程的多级组织；内存结构（共享、全局…）；同步机制；变量作用域
- 并行程序设计
  - Foster’s methodology 
  - 常见的数据划分方式；常见的并行算法设计思路

**复习安排**

1. 并行程序设计导论
   - 对照ppt、教材、复习笔记 ✔
   - 链接复习纲要
   - 4次理论作业
2. 数据并行体系结构
   - 对照ppt、可能看一下课本![image-20240630100420847](C:\Users\asus\Desktop\大三下\并行\并行复习.assets\image-20240630100420847.png)
3. CUDA编程模型
   - 看课件、复习笔记![image-20240630100435397](C:\Users\asus\Desktop\大三下\并行\并行复习.assets\image-20240630100435397.png)

[并行程序设计期末复习纲要_并行程序设计期末考试-CSDN博客](https://blog.csdn.net/LornaL0375/article/details/131263788)

看作业以及实验课作业

看网上试卷样例

- [【并行算法】考试样卷_并行计算选择题-CSDN博客](https://blog.csdn.net/qq_44762986/article/details/112253349)
- [天津大学2020级并行计算期末考试（线上）_天津大学并行计算-CSDN博客](https://blog.csdn.net/m0_53182948/article/details/125416133)

查漏补缺：编程题（平时理论作业、实验作业）接口（有说明）概念（cuda、openMP解释名词含有）





#### 当前进度：

- 数据并行体系结构主要讲了如何优化向量架构以及CUDA架构的一些介绍，可以等看完CUDA回来再做一次笔记加深印象

- CUDA看了一半了，到时候估计看不用多久就回去看《数据并行体系结构》



- 紧急！！！！！！！！！！！！！！！！！！！！

预测概念题

看cuda怎么优化

bank conflict

线程束

[CUDA：延迟隐藏详解_gpu通过片元切换来延迟隐藏-CSDN博客](https://blog.csdn.net/fb_help/article/details/81707216)

#### 出题

- 局部性：时间 空间
- 缓存一致性：写直达和写回
- cache映射方式：全相联、直接映射、组相联
- 冯诺依曼系统SISD：加入流水线，可将一条复杂指令用于多个数据对象，称为SIMD，加入多发射或硬件多线程，可将不同数据项应用于不同指令，成为MIMD
- 冯诺依曼瓶颈：主存和cpu分离，指令和数据在同一处理器
- 线程和进程：进程在多任务时切换耗时长，且不同进程间的数据不共享，线程在同一进程中共享资源，但各自需要一个私有程序计算器和函数调用栈，可以派生和合并子线程
- 虚拟存储器：在多任务系统中，程序共享主存，虚拟存储器使得主存可以作为辅存的缓存，通过分页，将虚拟页号映射到物理地址（使用页表/TLB）,保证程序内存不会重叠
- 指令级并行ILP：一般通过流水线和多发射实现，线程级并行TLP：通过硬件实现，是粗粒度并行，线程间切换延迟，短阻塞时处理器空闲，
- SIMD：单指令多数据流，阵列处理器和向量处理器：流水线结构，以向量为基本操作单元（不能处理不规则数据，可扩展型限制，比如不等于向量处理器长度的向量处理）（可处理特殊数据，比MIMD更节能，允许串行编程思维）
- SIMD 和 SIMT：simd数据必须连续，simt可分开寻址，且simt每个线程的向量元素是私有的
- MIMD：共享内存系统：集中共享（对称多处理器、一致存储访问系统）、分布式共享（非一致存储访问系统）；分布式内存系统（每个节点都有私有内存，通过消息机制传播）：大规模并行处理器系统、工作站机群系统
- cache一致性：监听cache一致性协议（通过一条总线，当某cache发生更新时则广播消息，其他cache监听共享总线，发现对应更新消息则同步更新）；基于目录的cache一致性协议（通过目录存储每个内存条的状态，当本地缓存读入时，对应目录项会更新，当发生变量更新时，则查询目录，将包含该变量的缓存行置为非法）
- 伪共享：当一个核更新高速缓存行时，使另一个核的高速缓存行失效，即使访问同一缓存行的不同数据，也无法访问，只能访问主存。
- SPMD指的是单程序多数据流，存在共享内存和分布式内存两种实现方式，
  - 共享内存：动态线程，主线程在收到请求派生线程，。。。，静态线程；
- 非确定性：输出顺序和竞争条件
- 阿姆达尔定律：除非将串行程序几乎全部并行化，否则无论增加多少个核，加速比都是受限的
- foster方法：划分、通信、凝聚（将任务和通信结合起来）、分配（通信量最小化）
- 可扩展性：强：核的增多不需要增大任务规模还能保持原有效率
- 路障：可通过忙等待和互斥量、信号量、条件变量实现



**[5分] 什么是GPU内存中的缓存模式和非缓存模式？两者有何区别？**

**答案**：

- **缓存模式**：默认模式，尝试在L1缓存命中，然后是L2缓存，最后是全局内存。加载粒度为128字节行。适用于需要频繁访问相同数据的情况。
- **非缓存模式**：使用编译选项 `–Xptxas –dlcm=cg`，尝试在L2缓存命中，然后是全局内存。加载粒度为32字节段。适用于避免L1缓存污染，数据访问模式较为分散的情况。

**[5分] 在CUDA编程中，如何实现高效的全局内存访问？**

**答案**：

- 争取完美合并，确保**warp在连续区域内访问**。
- **启动足够多的warp**以最大化总线的吞吐量。
- **多次加载可被流水化**。
- **重用索引**计算。
- **使用所有缓存**。

**[5分] 共享内存的主要用途是什么？**

**答案**：

- 块内线程间通信。
- 缓存数据以减少冗余的全局内存访问，类似于CPU缓存。
- 改善全局内存的访问模式。

**[5分] 解释什么是共享内存中的银行冲突，并举例说明如何避免银行冲突。**

**答案**：

- 银行冲突发生在多个线程尝试同时访问同一个内存银行时，这些访问会被串行化，导致性能下降。
- 避免银行冲突的一个方法是通过添加列填充，使得访问模式变得更均匀，从而避免同一时间对相同银行的访问。例如，在32x32矩阵列访问时添加列填充，可以避免32路银行冲突。

**[5分] 在GPU内存操作中，什么是加载粒度？如何影响性能？**

**答案**：

- 加载粒度指的是**一次内存加载操作所涉及的数据大小**。缓存模式下加载粒度为128字节行，非缓存模式下加载粒度为32字节段。
- 较大的加载粒度可以**提高内存访问的利用率**，减少内存操作的开销，但也可能**导致更多的无效数据加载**。如果访问模式良好，较大的加载粒度能显著提高性能。

**[5分] 什么是需求分页（Demand Paging），在Pascal及以上架构中如何实现？**

**答案**：

- **需求分页是指当访问某个未映射的内存页面时，系统动态地将所需页面加载到内存中**。Pascal及以上架构支持需求分页，可以超额分配GPU内存，分配大小可达到系统内存的大小。
- 通过`cudaMallocManaged`分配统一内存，**数据在CPU和GPU之间透明地迁移**。

**[5分] 如何利用共享内存优化CUDA程序的性能？**

**答案**：

- 通过将频繁访问的数据缓存到共享内存中，**减少对全局内存的访问次数**。
- 组织线程以避免共享内存的**银行冲突**。
- 充分利用共享内存的低延迟特性，加快线程间的**数据传递**。

**[5分] 什么是warp，在CUDA编程中如何优化warp的使用？**

**答案**：

- Warp是CUDA中**32个并行执行的线程的集合，是GPU调度的基本单位**。
- 优化warp的使用可以通过**确保所有线程在同一时间执行相同的指令，避免线程发散**。**组织内存访问模式以实现合并加载**，提高内存访问效率。

**[5分] 什么是对齐加载和乱序加载？它们对性能有何影响？**

**答案**：

- **对齐加载**：指线程**按顺序连续**地访问内存，内存地址是对齐的。性能较高，因为可以**充分利用缓存行**。
- **乱序加载**：指线程按不连续顺序访问内存，内存地址是乱序的。性能较低，因为会导致更多的缓存行请求，增加内存访问时间。

**[5分] 如何理解warp中的线程发散（Thread Divergence）？它对性能有何影响？**

**答案**：

- 线程发散指的是同一个warp中的**不同线程执行不同的指令路径**，这会导致**warp内的部分线程需要等待其他线程完成，降低并行度和执行效率**。
- 线程发散会显著降低性能，因为所有线程都需要等待最慢的线程完成。

**[5分] 解释共享内存银行冲突的概念，并说明如何通过改变访问模式来减少冲突。**

**答案**：

- 共享内存银行冲突发生在多个线程同时访问同一个内存银行时，这些访问需要被串行化处理，导致性能下降。
- 通过改变数据存储方式（例如，增加填充列）或优化访问模式（例如，确保线程访问不同的银行）可以减少银行冲突。

**[5分] 什么是全局同步问题？如何在CUDA编程中实现块间同步？**

**答案**：

- 全局同步问题指的是在**CUDA中无法直接实现跨块的线程同步**。
- 可以通过**内核分解策略**，将大任务分解为多个小任务，在每个任务之间实现同步，或者使用多个内核来达到同步效果。

**[5分] 如何使用循环展开技术优化CUDA程序？**

**答案**：

- 循环展开技术通过**手动展开循环体**，减少循环控制的开销和分支预测错误，**增加指令级并行度**。
- 在CUDA中，可以通过**展开最后一个warp的归约操作，减少同步和分支，提高性能**。

**[5分] 解释内存合并（Memory Coalescing）的概念及其对性能的影响。**

**答案**：

- 内存合并指的是将**多个线程的内存访问**合并为**一次内存访问操作**，以提高**内存带宽利用率**。
- 内存合并可以显著提高全局内存访问的效率，**减少内存访问的开销**，提高程序性能。

**[5分] 为什么在CUDA编程中，减少全局内存访问次数非常重要？如何实现这一目标？**

**答案**：

- 全局内存访问的**延迟较高**，**频繁**访问全局内存会显著降低程序性能。
- 通过使用**共享内存和寄存器缓存数据**，减少对全局内存的访问次数，可以显著提高性能。

