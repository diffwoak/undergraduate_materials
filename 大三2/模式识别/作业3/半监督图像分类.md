## **半监督图像分类**

### 实验内容

1. 阅读原始论文和相关参考资料，基于 Pytorch 动手实现 FixMatch 半监督图像分类算法，在 CIFAR-10 进行半监督图像分类实验，报告算法在分别使用 40,250, 4000 张标注数据的情况下的图像分类结果
2. 按照原始论文的设置，FixMatch 使用 WideResNet-28-2 作为 Backbone 网络，即深度为 28，扩展因子为 2，使用 CIFAR-10 作为数据集，可以参考现有代码的实现，算法核心步骤不能直接照抄！
3. 使用 TorchSSL 中提供的 FixMatch 的实现进行半监督训练和测试，对比自己实现的算法和 TorchSSL 中的实现的效果

### 实验过程

#### 一、FixMatch实现

##### 算法步骤

<img src="C:\Users\asus\Desktop\大三下\模式识别\作业3\半监督图像分类.assets\image-20240625225543110.png" alt="image-20240625225543110" style="zoom: 50%;" />

1. **有标签数据训练**：
   - 对于每个有标签数据，计算模型预测与真实标签之间的交叉熵损失。
2. **无标签数据训练**：
   - 数据增强：
     - 对每个无标签数据样本，生成一个弱增强版本和一个强增强版本。
   - 伪标签生成：
     - 将弱增强版本的图像输入模型，获取预测分布。
     - 从预测分布中提取伪标签（即选择概率最高的类别作为伪标签）。
   - 一致性损失计算：
     - 将强增强版本的图像输入模型，获取预测分布。
     - 计算强增强版本的预测分布与伪标签之间的交叉熵损失。
3. **总损失计算和反向传播**：
   - 结合有标签数据的交叉熵损失和无标签数据的一致性损失，计算总损失。
   - 使用反向传播算法更新模型参数。

##### 核心代码

- 对无标签数据集使用弱增强与强增强:弱扩增与有标签的数据处理方式类似，直接使用翻转和裁剪技术；强扩增还使用了RandAugmentMC 算法进行数据增强

```python
# 有标签数据
transform_labeled = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(size=32,
                          padding=int(32*0.125),
                          padding_mode='reflect'),
    transforms.ToTensor(),
    transforms.Normalize(mean=cifar10_mean, std=cifar10_std)
])
# 无标签弱增强
self.weak = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(size=32,
                          padding=int(32*0.125),
                          padding_mode='reflect')])
# 无标签强增强
self.strong = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(size=32,
                          padding=int(32*0.125),
                          padding_mode='reflect'),
    RandAugmentMC(n=2, m=10)])
```

- 训练基本框架如下：代码展示有所简化

```python
# 获取数据集
labeled_dataset, unlabeled_dataset, test_dataset = DATASET_GETTERS[args.dataset](
        args, './data')
# 定义数据加载器
labeled_trainloader = DataLoader(
    labeled_dataset,
    sampler=RandomSampler(labeled_dataset),
    batch_size=args.batch_size,
    num_workers=4,
    drop_last=True)
unlabeled_trainloader = DataLoader(
    unlabeled_dataset,
    sampler=RandomSampler(unlabeled_dataset),
    batch_size=args.batch_size*args.mu,
    num_workers=4,
    drop_last=True)
# 定义优化器
optimizer = optim.SGD(grouped_parameters, lr=args.lr,momentum=0.9)
scheduler = get_cosine_schedule(optimizer, args.total_steps)
# 定义迭代器
labeled_iter = iter(labeled_trainloader)
unlabeled_iter = iter(unlabeled_trainloader)
# 进入循环
    # 迭代得到训练数据
    inputs_x, targets_x = labeled_iter.next()
    (inputs_u_w, inputs_u_s), _ = unlabeled_iter.next()
    # 输入数据
    inputs = torch.cat((inputs_x, inputs_u_w, inputs_u_s))
	# 分离输出数据
    logits = model(inputs)
    logits_x = logits[:batch_size]	# 有标签
    logits_u_w, logits_u_s = logits[batch_size:].chunk(2)	# 无标签
    # 损失函数cross_entropy
    # 有标签损失:Lx
    Lx = F.cross_entropy(logits_x, targets_x, reduction='mean')
    # 无标签损失:以弱增强输入筛选出可训练数据,再用强增强输出计算损失函数Lu
    pseudo_label = torch.softmax(logits_u_w.detach(), dim=-1)
    max_probs, targets_u = torch.max(pseudo_label, dim=-1)
    mask = max_probs.ge(args.threshold).float()
    Lu = (F.cross_entropy(logits_u_s, targets_u, reduction='none') * mask).mean()
    loss = Lx + args.lambda_u * Lu
    # 反向传播
    loss.backward()
    # 更新参数模型
    optimizer.step()
    scheduler.step()
```

- 训练细节

  - ``use-ema``：指数移动平均模型，EMA 模型通过对模型参数进行指数加权平均来平滑参数更新过程，从而减少参数更新的波动性，提高模型的泛化能力。

    如果不使用ema模型会出现以下loss为nan的情况

    ![image-20240626221824076](C:\Users\asus\Desktop\大三下\模式识别\作业3\半监督图像分类.assets\image-20240626221824076.png)

  - ``weight_decay``: 对所有不包含 ``bias`` 和 ``bn`` 的参数应用权重衰减，来防止过拟合

  - 关于数据如何输入模型，考虑到如果有标签、无标签弱增强、无标签强增强 3 份数据分别输入网络，在批量归一化中会出现 3 种不同分布，使模型难以进一步拟合，因此在源代码中采取将 3 种数据混合的方式，使用 `interleave` 和 `de_interleave` 是在一个批次内混合标记数据和无标记数据，以便共同计算批量归一化的统计量，从而提高模型训练的稳定性和效果
  
    ```python
    # (a, b, c)->(a/size, size, b, c)->(size, a/size, b, c)->(size * a/size, b, c)
    def interleave(x, size):
        s = list(x.shape)
        return x.reshape([-1, size] + s[1:]).transpose(0, 1).reshape([-1] + s[1:])
    # 分离输出 interleave的逆过程
    def de_interleave(x, size):
        s = list(x.shape)
        return x.reshape([size, -1] + s[1:]).transpose(0, 1).reshape([-1] + s[1:])
    ```
  

##### 运行结果

```bash
python train.py --num-labeled 4000 --epochs 500
```

开始运行：

![image-20240629200029349](C:\Users\asus\Desktop\大三下\模式识别\作业3\半监督图像分类.assets\image-20240629200029349.png)

时间原因只在500epoches中比较不同标注数据量的分类结果对比：

<img src="C:\Users\asus\Desktop\大三下\模式识别\作业3\半监督图像分类.assets\plt_acc_40.jpg" alt="plt_acc_40" style="zoom: 67%;" />

<img src="C:\Users\asus\Desktop\大三下\模式识别\作业3\半监督图像分类.assets\plt_acc_250 (1)-17195903754097.jpg" alt="plt_acc_250 (1)" style="zoom: 67%;" />

<img src="C:\Users\asus\Desktop\大三下\模式识别\作业3\半监督图像分类.assets\plt_acc_4000 (1)-17195903231615.jpg" alt="plt_acc_4000 (1)" style="zoom: 67%;" />

其中有标签数量40在epoches=500内未能收敛，由于运行时间较长，且在之后epoch中未能及时记录运行数据，因此以上图片展示只展示到500个epoches，之后的训练效果可参考下图：标签数量40在训练到750epoches的测试准确率达到90.43%.

![image-20240629183131332](C:\Users\asus\Desktop\大三下\模式识别\作业3\半监督图像分类.assets\image-20240629183131332.png)

### 二、TorchSSL对比

TorchSSL配置环境后运行

```bash
# labeled 4000
python fixmatch.py --c config/fixmatch/fixmatch_cifar10_4000_0.yaml
# labeled 250
python fixmatch.py --c config/fixmatch/fixmatch_cifar10_250_0.yaml
# labeled 40
python fixmatch.py --c config/fixmatch/fixmatch_cifar10_40_0.yaml
```

开始运行：

![image-20240627102927862](C:\Users\asus\Desktop\大三下\模式识别\作业3\半监督图像分类.assets\image-20240627102927862.png)

由于实验参数不完全相同，只对比最终测试结果：

| labeled  | 40    | 250   | 4000  |
| -------- | ----- | ----- | ----- |
| FixMatch | 90.54 | 93.06 | 94.29 |
| TorchSSL | 90.58 | 92.58 | 94.05 |

可以看出实现的FixMatch算法与TorchSSL提供的FixMatch训练结果相差不大，TorchSSL使用默认参数没做过多调整，导致准确率略低。在40个样本时测试结果小于正常预期值，原因在于设置的epoches数偏小，训练未完全收敛。后续改进可参考FixMatch源代码中混合精度训练减少舍入误差的问题，以及调整其他参数比如使用余弦退火策略时加入预热阶段，调整batch-size大小观察对准确率的变化等。

### 三、对比 FixMatch 和 MixMatch

1. MixMatch 和 FixMatch 使用的半监督学习方法不同。MixMatch使用了 Mixup技术将一个样本与另一个随机样本的特征进行混合，并且通过最大化熵损失函数来优化网络，以提高模型的泛化能力；而 FixMatch则使用了自监督学习技术，选择置信度高的无标签数据加入到有标签数据中进行训练网络。

2. MixMatch 的训练过程需要迭代多次才能得到结果，每次迭代都需要对全部无标签数据进行处理；而 FixMatch 只需要迭代一次就能够输出，并且只对部分无标签数据进行处理。
